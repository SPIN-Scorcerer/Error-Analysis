# Error-Analysis

In contrast with keyword counts often used for speech in noise tasks (e.g., Chandrasekaran et al., 2015; Reetzke et al., 2016; Smayda et al., 2016; Van Engen et al., 2012; Xie et al., 2014, 2015), this analysis examined both word- and morpheme-level errors. Participants' typed responses and their respective target sentences were aligned by a custom implementation of the Needleman-Wunsch algorithm, a dynamic global alignment algorithm primarily utilized for aligning protein and nucleotide sequences in bioinformatics (Needleman & Wunsch, 1970). In the original algorithm, three scores govern the optimal alignment: a match award, a mismatch penalty, and a gap penalty. The optimal alignment is chosen by maximizing matches and minimizing mismatches and gaps. Our implementation, which compares sentences at the word-level, adds one additional award for pairs of words with Levenshtein distances less than or equal to two. This encourages alignments of words with similar spellings such as some homonyms and rhymes. The alignment step produces two optimally-aligned strings with equal numbers of tokens, taking into account gaps, which are represented by the token "-". See Figure 1 for an illustration. Word errors are then calculated by examining each word pairing in the alignment. 

All words were lemmatized and tagged for part of speech by the Pattern module (De Smedt & Daelemans, 2012), a Python toolkit which quickly and accurately performs part-of-speech tagging, lemmatization, spelling suggestions, and other natural language processing (NLP) tasks in Python 2.7.10. This module relies on statistical approaches to these NLP problems; thus, its results are occasionally inaccurate. Certain errors and inconsistencies in the Pattern module were revised in our code. For example, the word “laid” was manually lemmatized, as the Pattern module did not accurately recognize “laid” as a conjugation of “lay”. If a pair of aligned words matched in their root forms but not in the original target and response, a morphemic error was recorded. Additionally, if both words were function words or if a function word was aligned with a gap token, a morphemic error was recorded, as function word errors were included in the morphemic error analysis. If both words were content words or if a content word was aligned with a gap token, a content word error was recorded. If one word in a pairing was a function word and the other a content word, one morphemic error and one content error were recorded. 

Finally, if none of the roots for content words from the key sentence appeared in the response, the entire trial was reclassified as “Did Not Hear” (DNH). This distinction is important because in some cases, participants failed to transcribe any response at all or fully transcribed a distractor sentence instead of the target. These whole-response level errors are aggregated separately, as they do not reflect specific word-level changes in the perceived signal.
